{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "from util import DataFrameBase, xlim_expand\n",
    "from tbtools.dev import IProgressBar, ProgressBar, subreload\n",
    "from tbtools.iter import replace_repetitions, tbfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figspath = os.environ['HOME'] + '/Dropbox/DTU/4th Semester/figs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_parent = os.environ['HOME'] + '/Speciale/data/exported/'\n",
    "dbs = ('NN_1_10', 'NN_26', 'NN_CLC')\n",
    "\n",
    "# https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "global_settings = {\n",
    "    'delimiter':';', \n",
    "    'encoding':'cp1252',\n",
    "    'infer_datetime_format':True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dates(*args):\n",
    "    return {'parse_dates': list(args)}\n",
    "\n",
    "datotid = parse_dates('DatoTid')\n",
    "timestamp = parse_dates('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All three DBs have the same tables\n",
    "s\n",
    "\n",
    "clc = DataFrameBase(db_parent, 'clc', \n",
    "                    global_settings=global_settings, \n",
    "                    table_settings=table_settings)\n",
    "\n",
    "b1 = DataFrameBase(db_parent, '1', \n",
    "                   global_settings=global_settings, \n",
    "                   table_settings=table_settings)\n",
    "\n",
    "b2 = DataFrameBase(db_parent, '2', \n",
    "                   global_settings=global_settings, \n",
    "                   table_settings=table_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check normalization method for whether it is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_sql?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_df(df, intended_index):\n",
    "    \"\"\"df is a dataframe\n",
    "    intended_index is a column name; this column will\n",
    "        be used as index in the normalized df. If not\n",
    "        defined, no new index is set.\n",
    "    \n",
    "    Discards rows that have all the same information, \n",
    "        including timestamps.\n",
    "    Discards rows and column with only NaNs.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.dropna(0, 'all').dropna(1, 'all')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    if intended_index:\n",
    "        df.set_index(intended_index, verify_integrity=True, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[\"xx\",1,2,3], [\"f\", 1,np.nan,4], [\"j\", 1,np.nan,4]], \n",
    "                  columns=list('abcd'), \n",
    "                  index=[1,2,2])\n",
    "normalize_df(df, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ah = clc['AlmHist'].set_index('DatoTid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "norm = normalize_df(ah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ah.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ah.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(norm.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(norm.ix[ah.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ah.AlmState == norm.ix[ah.index].AlmState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbs = (clc, b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all known DateTime columns into a list per database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timecols = dict([(db.name, []) for db in dbs])\n",
    "\n",
    "for k in IProgressBar(table_settings):\n",
    "    datecols = table_settings[k]['parse_dates']\n",
    "    for db in dbs:\n",
    "        for v in datecols:\n",
    "            timecols[db.name].append(db[k][v])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each db, concatenate its time columns to one long column,\n",
    "and resample it to be the number of timecol entries per day.\n",
    "\n",
    "Dub this the `activity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activity = {}\n",
    "\n",
    "for k in IProgressBar(timecols):\n",
    "    ser = pd.concat(timecols[k], ignore_index=True)\n",
    "    df = pd.concat([ser, pd.Series(np.ones(ser.shape))], axis=1).set_index(0)\n",
    "    df.columns = [k]\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.resample('D', 'sum')\n",
    "    activity[k] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the number of times each day appears in each db together in a DataFrame\n",
    "\n",
    "Dub it `day_seen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "day_seen = pd.concat(activity.values(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activation(df):\n",
    "    \"\"\"df is a dataframe\n",
    "    each column holds counts\n",
    "    This is turned into an indicator: > 0 or not\n",
    "    And the values in each\n",
    "    \"\"\"\n",
    "    df[df.gt(0)] = 1\n",
    "    for i, col in enumerate(df):\n",
    "        df[col] *= i+1\n",
    "    df[df.le(0)] = np.float('nan')\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make indicator variables to plot the dates with activity for each database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indicator = activation(day_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.plt.savefig?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot = indicator.plot(style='.', ylim=(0,4), alpha=0.5, figsize=(12,4))\n",
    "# plot.set_title('Dates covered by timestamps in the three initial databases')\n",
    "xlim_expand(plot, 15)\n",
    "plot.set_xlabel('')\n",
    "plot.tick_params(\n",
    "    axis='y',        # changes apply to the x-axis\n",
    "    which='both',    # both major and minor ticks are affected\n",
    "    left='off',      # ticks along the bottom edge are off\n",
    "    right='off',     # ticks along the top edge are off\n",
    "    labelleft='off') # labels along the left edge are off\n",
    "sns.plt.tight_layout()\n",
    "sns.plt.savefig(figspath + '3db_covered.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts_differ = mdf[(mdf.iloc[:,0] != mdf.iloc[:,1]) | \n",
    "                (mdf.iloc[:,2] != mdf.iloc[:,1]) |\n",
    "                (mdf.iloc[:,0] != mdf.iloc[:,2])].stack(-1)\n",
    "\n",
    "plot = ts_differ.unstack().plot(style='o', alpha=0.5,  figsize=(12,4))\n",
    "# plot.set_title('Number of timestamps per database for days where they differ')\n",
    "plot.set_ylabel('Number of timestamps on day')\n",
    "plot.set_xlabel('')\n",
    "xlim_expand(plot, 10)\n",
    "sns.plt.tight_layout()\n",
    "sns.plt.savefig(figspath + '3db_difference.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Consider the differences in the week in the beginning of July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ahc = clc.AlmHist.set_index('DatoTid')\n",
    "ah1 = b1.AlmHist.set_index('DatoTid')\n",
    "ah2 = b2.AlmHist.set_index('DatoTid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = clc.AlmHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aggregate_activity(resample_how='D', default_value=0, **dfs):\n",
    "    \"\"\"Takes named dataframes with DateTime index, and\n",
    "    returns a single dataframe with an indicator variable\n",
    "    for each input df, showing whether that df had an entry\n",
    "    in the time slot.\n",
    "    \"\"\"\n",
    "    mindt, maxdt = None, None\n",
    "    for n in dfs:\n",
    "        s = dfs[n].index\n",
    "        if mindt is None:\n",
    "            mindt, maxdt = s.min(), s.max()\n",
    "            continue\n",
    "        mindt = min(mindt, s.min())\n",
    "        maxdt = max(maxdt, s.max())\n",
    "    \n",
    "    index = pd.date_range(mindt, maxdt, freq=resample_how, normalize=True)\n",
    "    \n",
    "    df = pd.DataFrame({col:default_value for col in dfs}, index=index)\n",
    "    \n",
    "    for n in dfs:\n",
    "#         s = (dfs[n].resample(resample_how, 'count') > 0).max(axis=1)\n",
    "        s = (dfs[n].resample(resample_how, 'count')).max(axis=1)\n",
    "        df.loc[s.index, n] = s\n",
    "        \n",
    "    agree = np.ones(len(df))\n",
    "    for i, (label, v) in enumerate(df.iterrows()):\n",
    "        if not all(v == v[0]):\n",
    "            agree[i] = 0\n",
    "            continue\n",
    "        if all(v == 0):\n",
    "            continue\n",
    "        subsets = [df[str(label.date())] for df in dfs.values()]\n",
    "        if not functionally_equal(subsets):\n",
    "            agree[i] = 0\n",
    "        \n",
    "    df['agree'] = agree * df.max().max()\n",
    "#     compare_content(list(dfs.values()), index) * df.max().max()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def compare_activity(resample_how='D', title='no title', **dfs):\n",
    "    df = aggregate_activity(**dfs, resample_how=resample_how)\n",
    "    \n",
    "    labels = [d.strftime('%b %d') for i,d in enumerate(df.index)]\n",
    "    labels = list(tbfilter(labels, [1,0], repl=['']))\n",
    "    \n",
    "    figwidth = len(df)/1.5#3.5\n",
    "    sns.plt.figure(figsize=(figwidth,5))\n",
    "    cm = sns.heatmap(df.T, \n",
    "                     xticklabels=labels,\n",
    "                     linewidths=0.5,\n",
    "                     cbar=False,\n",
    "                     square=True,\n",
    "                     annot=True, fmt='.0f')\n",
    "    cm.set_title(title)\n",
    "    cm.set_xlabel('Date in 2012')\n",
    "\n",
    "dbs = (('clc', clc), ('b1',b1), ('b2',b2))\n",
    "\n",
    "def functionally_equal(dfs):\n",
    "    dfs = iter(normalize_df(df) for df in dfs)\n",
    "    canon = next(dfs)\n",
    "    for d in dfs:\n",
    "        try:\n",
    "            pd.util.testing.assert_frame_equal(canon, d)\n",
    "        except AssertionError:\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def compare_content(dfs, major_index):\n",
    "    \"\"\"Takes a list of dataframes\n",
    "    Outputs a list indicating for each item in major_index\n",
    "    whether the content in all of them is exactly the same, \n",
    "    after sorting index, removing nans, and removing duplicates.\n",
    "    \"\"\"\n",
    "    dfs = list(map(normalize_df, dfs))\n",
    "    \n",
    "    labels = [str(i.date()) for i in major_index]\n",
    "    \n",
    "    output = np.ones(len(major_index))\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        continue\n",
    "        has_label = [(label in d.index) for d in dfs]\n",
    "        \n",
    "        if not all(has_label):\n",
    "            if any(has_label):\n",
    "                # Some dfs have data under this label, while\n",
    "                # other do not. They do not agree.\n",
    "                output[i] = 0\n",
    "            continue\n",
    "        \n",
    "        parts = iter(df[label] for df in dfs)\n",
    "        canon = next(parts)\n",
    "        \n",
    "        for p in parts:\n",
    "            try:\n",
    "                pass\n",
    "#                 pd.util.testing.assert_frame_equal(canon, p)\n",
    "            except AssertionError:\n",
    "                output[i] = 0\n",
    "                break\n",
    "        \n",
    "#         if not all((len(canon) == len(p)) for p in parts[1:]):\n",
    "#             output[i] = 0#or \\\n",
    "#             continue\n",
    "#         if not all((canon.index == p.index).all() for p in parts[1:]):\n",
    "#             output[i] = 0#or \\\n",
    "#             continue\n",
    "#         if not all((canon == p).all().all() for p in parts[1:]):\n",
    "#             output[i] = 0\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def normalize_df(df):\n",
    "    indexname = df.index.name or 'index'\n",
    "    \n",
    "    # make sure to take indices into account when dropping dupes\n",
    "    return df.fillna(0).\\\n",
    "              reset_index().\\\n",
    "              drop_duplicates().\\\n",
    "              set_index(indexname).\\\n",
    "              sort_index()\n",
    "        \n",
    "def compare_table(table_name):\n",
    "    pds = table_settings[table_name]['parse_dates']\n",
    "    for pd in pds:\n",
    "        title = '{}: {}'.format(table_name, pd)\n",
    "        tabs = {n:db[table_name].set_index(pd) for n,db in dbs}\n",
    "        lengths = [len(tab) for tab in tabs.values()]\n",
    "\n",
    "        if all([L==0 for L in lengths]):\n",
    "            print('Skipping {}: No data.'.format(table_name))\n",
    "            return\n",
    "        \n",
    "        compare_activity(title=title, **tabs)\n",
    "    \n",
    "def compare_all_tables():\n",
    "    for t in IProgressBar(table_settings):\n",
    "#     for t in table_settings:\n",
    "        compare_table(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_table('AlmHist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clc.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clc.efterkontrol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = b1.AlmHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b2.RaavareDB.plot(x='Timestamp', y='Vaegt_Bemaerkning', style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "compare_all_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_all_tables() # with soft counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Sep 01 (or 02, 03, 04, 05) for AlmHist in all three databases. How do they differ?\n",
    "\n",
    "In summary, they are exactly equal, when you remember to fillna and sort_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day = '2012-09-01'\n",
    "tables = [('clc', ahc), ('b1', ah1), ('b2', ah2)]\n",
    "\n",
    "def prep(df):\n",
    "    return df.sort_index().fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_equality(day):\n",
    "    dfs = [(name, prep(d[day])) for name,d in tables]\n",
    "    \n",
    "    eq = []\n",
    "    for (n1, df1), (n2, df2) in combinations(dfs, 2):\n",
    "        try:\n",
    "            e = all(df1 == df2)\n",
    "        except:\n",
    "            e = False\n",
    "        eq.append(e)\n",
    "        if not e:\n",
    "            print('{} and {} not equal on {}'.format(n1, n2, day))\n",
    "    \n",
    "    print('All equal on day {}?'.format(day), all(eq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('2012-09-01', '2012-09-08'):\n",
    "    evaluate_equality(str(day.date()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(hc), len(h1), len(h2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Where the datetime indices match, i.e. where the timestamps are the same, is the data also the same?\n",
    "- yes.\n",
    "    + For B1 and B2, the data is exactly the same for the whole day.\n",
    "    + When they are sorted by index, so that the rows are ordered by their DatoTid, everything is the same.\n",
    "    + False earlier conclusion: *For CLC and the others, the overlap is 1038 perfect matches of 1302, where the 264 remaining have odd timestamps.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2012-09-02'\n",
    "\n",
    "all(hc.sort_index().fillna(0) == h1.sort_index().fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "dfs = [('clc', hc.sort_index().fillna(-1)), ('b1', h1.sort_index().fillna(-1)), ('b2', h2.sort_index())]\n",
    "# Where the indices match, are they equal?\n",
    "for (n1, df1), (n2, df2) in combinations(dfs, 2):\n",
    "    eq = df1.index == df2.index\n",
    "    print('Comparing {} and {} AlmHist on {}:'.format(n1, n2, day), \n",
    "          all(df1[eq].fillna(0) == df2[eq].fillna(0)))\n",
    "    print('\\tOverlap is {}/{}'.format(sum(eq), len(df1)))\n",
    "    \n",
    "# eq = h1.index == hc.index\n",
    "# print('Comparing b1 and clc AlmHist on {}:'.format(day), all(h1[eq].fillna(0) == hc[eq].fillna(0)))\n",
    "# print('Overlap is {}/{}'.format(sum(eq), len(h1)))\n",
    "# eq = h2.index == hc.index\n",
    "# print('Comparing b2 and clc AlmHist on {}:'.format(day), all(h2[eq].fillna(0) == hc[eq].fillna(0)))\n",
    "# print('Overlap is {}/{}'.format(sum(eq), len(h2)))\n",
    "# print('Comparing b2 and clc AlmHist on {}:'.format(day), all(h2[eq].fillna(0) == hc[eq].fillna(0)))\n",
    "# print('Overlap is {}/{}'.format(sum(eq), len(h2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With correct fillna and sort_index, how often do the three databases concur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hc = clc.AlmHist.set_index('DatoTid').sort_index().fillna(-1)\n",
    "h1 = b1.AlmHist.set_index('DatoTid').sort_index().fillna(-1)\n",
    "h2 = b2.AlmHist.set_index('DatoTid').sort_index().fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- According to index.isin,\n",
    "    + h1 is a superset of h2\n",
    "    + hc is a superset of neither, or at least doesn't completely contain either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('hc number of dupes {}'.format(len(hc) - len(hc.reset_index().drop_duplicates())))\n",
    "print('h1 number of dupes {}'.format(len(h1) - len(h1.reset_index().drop_duplicates())))\n",
    "print('h2 number of dupes {}'.format(len(h2) - len(h2.reset_index().drop_duplicates())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('hc number of nan {}'.format(len(hc) - len(hc.dropna())))\n",
    "print('h1 number of nan {}'.format(len(h1) - len(h1.dropna())))\n",
    "print('h2 number of nan {}'.format(len(h2) - len(h2.dropna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to merge two dataframes with similar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.array([[1,2,4],[4,5,6], [1,1,1]]), columns=['a','b','c'], index=[1,2,15])\n",
    "df2 = pd.DataFrame(np.array([[1,2,3],[1,1,1], [14,15,16]]), columns=['a','b','c'], index=[1,15, 3])\n",
    "\n",
    "res = df1.align(df2) #Â Get df1 and df2, with aligned indices and lots of NaNs\n",
    "res = pd.concat(res, join='outer') # Concatenate them\n",
    "# Clean up\n",
    "res = res.dropna()\n",
    "res = res.sort_index()\n",
    "\n",
    "res = res.drop_duplicates()\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we get when we align-concat-dropna-dropdupes on the three AlmHist tables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Raw len {} {}'.format(len(hc), len(h1)))\n",
    "res = hc.align(h1) # Get df1 and df2, with aligned indices and lots of NaNs\n",
    "print('aligned len {}'.format(len(res[0])))\n",
    "res = pd.concat(res, join='outer') # Concatenate them\n",
    "print('concat len {}'.format(len(res)))\n",
    "# Clean up\n",
    "res = res.dropna()\n",
    "print('dropped na len {}'.format(len(res)))\n",
    "res = res.sort_index()\n",
    "indexname = res.index.name or 'index'\n",
    "res = res.reset_index().drop_duplicates().set_index(indexname)\n",
    "print('dropped duplicates len {}'.format(len(res)))\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that hc and h1 have an overlap of \n",
    "\n",
    "sum of original lenghts - final length $= (3087964+829529) - 3834292 = 83201$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('merging h2 into the merged hc h1')\n",
    "print('Raw len {} {}'.format(len(res), len(h2)))\n",
    "res2 = res.align(h2)\n",
    "print('aligned len {}'.format(len(res2[0])))\n",
    "res2 = pd.concat(res2, join='outer') # Concatenate them\n",
    "print('concat len {}'.format(len(res2)))\n",
    "# Clean up\n",
    "res2 = res2.dropna()\n",
    "print('dropped na len {}'.format(len(res2)))\n",
    "res2 = res2.sort_index()\n",
    "indexname = res2.index.name or 'index'\n",
    "res2 = res2.reset_index().drop_duplicates().set_index(indexname)\n",
    "print('dropped duplicates len {}'.format(len(res2)))\n",
    "# res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h2 had nothing to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(res.resample('D', 'count') > 0).plot(style='.', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
